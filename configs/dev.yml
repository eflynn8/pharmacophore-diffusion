training:
  output_dir: runs/
  batch_size: 32
  weight_decay: 1.0e-12
  num_workers: 0
  validation_splits: [2]
  trainer_args:
    max_epochs: 10
    accelerator: gpu
    devices: 1
    accumulate_grad_batches: 1
    limit_val_batches: 1.0

  evaluation:
    pharms_per_pocket: 2
    n_pockets: 8
    sample_interval: 0.5 # how often to sample molecules during training, measured in epochs
    val_loss_interval: 0.8 # how often to compute validation set loss during training, measured in epochs

lr_scheduler:
  # to turn off warmup and restarts, set both warmup_length and restart_interval to 0
  base_lr: 1.0e-3
  warmup_length: 0
  restart_interval: 0 # 0 means no restart
  restart_type: 'linear'
  weight_decay: 1.0e-12
  monitor: 'val total loss'
  interval: 'step'
  frequency: 100 #this needs to be greater than (val_loss_ineterval * number of train iteration per epoch)
  reducelronplateau:
    mode: 'min'
    factor: 0.1
    patience: 20
    min_lr: 1.0e-5
    verbose: True

checkpointing:
  save_last: True
  save_top_k: 3
  # monitor: 'val_total_loss'
  monitor: 'val total loss'
  every_n_epochs: 1

wandb:
  project: pharm-gen
  group: "dev"
  name: "dev run"
  mode: disabled # can be disabled, online, offline

dataset:
  # TODO: no dataset class actually accesses this information
  # data_files: ['/home/elf152/Documents/pharmacoflow/it2_tt_v1.3_0_test0_ph.pkl', '/home/elf152/Documents/pharmacoflow/it2_tt_v1.3_0_test1_ph.pkl', '/home/elf152/Documents/pharmacoflow/it2_tt_v1.3_0_test2_ph.pkl']
  raw_data_dir: 'data/crossdocked_raw/'
  processed_data_dir: 'data/crossdocked_processed_dev'
  # data_files: ['data/crossdocked_pharm_extracted/it2_tt_v1.3_0_test0_ph.pkl.gz']
  # rec_file: 'data/crossdocked_pharm_extracted/receptors.pkl.gz'
  prot_elements: ['C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'B', 'D'] # ['C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'Mg', 'Mn', 'Zn', 'Ca', 'Fe', 'B']
  ph_type_map: [    'Aromatic', 'HydrogenDonor', 'HydrogenAcceptor', 'PositiveIon', 'NegativeIon', 'Hydrophobic']
  pocket_cutoff: 8 # angstroms
  min_pharm_centers: 3
  dataset_size: 1000 # used only for debugging
  subsample_pharms: True
  subsample_min: 4
  subsample_max: 8
  
  
graph:
  # TODO: cleaner graph specification
  radius: {'pp': 8, 'pf': 8, 'fp': 8, 'ff': 9}
  knn: {'pp': 10, 'pf': 10, 'fp': 10, 'ff': 10}
  krandom:
    pp: 10
  temp:
    pp: 1.25
  graph_types:
    pp: 'random-knn'
    pf: 'radius'
    ff: 'radius'

pharmacoforge:
  model_class: flow-matching

flow-matching:
  time_scaled_loss: False
  vf_config: # kwargs for FMVectorField
    node_scalar_dim: 64
    node_vector_dim: 16
    convs_per_update: 1
    n_recycles: 1
    n_updates: 3
    separate_updaters: true
    time_embedding_dim: 1
    type_embedding_dim: 64
    conv_config: # kwargs for GVPMultiEdgeConv
      cp_dim: 0
      n_message_gvps: 3
      n_update_gvps: 3
      n_expansion_gvps: 3
      # the next four arguments are strictly for graph attention, which is not currently implemented
      # attention: False
      # n_kq_gvps: 3
      # s_kq_dim: 32
      # v_kq_dim: 32
      message_norm: 100
      rbf_dmax: 16
      rbf_dim: 42
      s_message_dim: null
      v_message_dim: null

diffusion:
  n_timesteps: 100
  precision: 1.0e-5
  pharm_feat_norm_constant: 1
  endpoint_param_feat: False
  endpoint_param_coord: False
  weighted_loss: False
  remove_com_noising: True

dynamics:
  vector_size: 16
  n_convs: 2
  n_hidden_scalars: 128
  message_norm: 'mean'
  dropout: 0.1
  n_message_gvps: 3 # the number of GVPs to chain together for the message function
  n_update_gvps: 2 # the number of GVPs to chain together for the update function
  n_noise_gvps: 4 # the number of GVPs to chain together for the noise prediction block

rec_encoder_loss:
  loss_type: 'optimal_transport' # can be optimal_transport, gaussian_repulsion, hinge, or none
